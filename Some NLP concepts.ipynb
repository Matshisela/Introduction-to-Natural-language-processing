{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5977a8",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "\"Natural language processing is an area of research in computer science and artificial intelligence (AI) concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data (numbers) that a computer can use to learn about the world. And this understanding of the world is sometimes used\n",
    "to generate natural language text that reflects that understanding.\"- Natural Language Processing in action, pg 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b3efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beac64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"'My name is Ntandoyenkosi Matshisela, a 30 year old data analyst from Zimbabwe. I did my Masters degree at the National University of Science and Technology, Zimbabwe, where I specialised in Operations Research and Statistics, 2018. Prior to this I did a BSc in Operations Research and Statistics finishing it in 2015. My research interests are statistical computing and machine learning.üòä \\n Most of the times, like 5 times a week, I tweet about #Python, #Rstats and #R. The tweeter handle is @matshiselaüòÇ. \\n ‚óò≈¶, ‚Ç¶ ‚úî \\n  I love giftsüéÅ, pizza üçï, sandwichü•™'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9405a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'My name is Ntandoyenkosi Matshisela, a 30 year old data analyst from Zimbabwe. I did my Masters degree at the National University of Science and Technology, Zimbabwe, where I specialised in Operations Research and Statistics, 2018. Prior to this I did a BSc in Operations Research and Statistics finishing it in 2015. My research interests are statistical computing and machine learning.üòä \n",
      " Most of the times, like 5 times a week, I tweet about #Python, #Rstats and #R. The tweeter handle is @matshiselaüòÇ. \n",
      " ‚óò≈¶, ‚Ç¶ ‚úî \n",
      "  I love giftsüéÅ, pizza üçï, sandwichü•™'\n"
     ]
    }
   ],
   "source": [
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebca4b",
   "metadata": {},
   "source": [
    "## Searching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dd81b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 3), match='My'>\n"
     ]
    }
   ],
   "source": [
    "# Let us match words\n",
    "word_regex = r\"\\w+\"\n",
    "print(re.search(word_regex, sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d373806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(40, 42), match='30'>\n"
     ]
    }
   ],
   "source": [
    "number_regex = \"\\d+\"\n",
    "print(re.search(number_regex, sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a17f0",
   "metadata": {},
   "source": [
    "## Findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810d37e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'Ntandoyenkosi', 'Matshisela', 'Zimbabwe', 'Masters', 'National', 'University', 'Science', 'Technology', 'Zimbabwe', 'Operations', 'Research', 'Statistics', 'Prior', 'BSc', 'Operations', 'Research', 'Statistics', 'My', 'Most', 'Python', 'Rstats', 'The']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "capital_words = r\"[A-Z]\\w+\"\n",
    "\n",
    "print(re.findall(capital_words, sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ecf9a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'is', 'tandoyenkosi', 'atshisela', 'year', 'old', 'data', 'analyst', 'from', 'imbabwe', 'did', 'my', 'asters', 'degree', 'at', 'the', 'ational', 'niversity', 'of', 'cience', 'and', 'echnology', 'imbabwe', 'where', 'specialised', 'in', 'perations', 'esearch', 'and', 'tatistics', 'rior', 'to', 'this', 'did', 'in', 'perations', 'esearch', 'and', 'tatistics', 'finishing', 'it', 'in', 'research', 'interests', 'are', 'statistical', 'computing', 'and', 'machine', 'learning', 'ost', 'of', 'the', 'times', 'like', 'times', 'week', 'tweet', 'about', 'ython', 'stats', 'and', 'he', 'tweeter', 'handle', 'is', 'matshisela', 'love', 'gifts', 'pizza', 'sandwich']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "lower_cases = r\"[a-z]\\w+\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.findall(lower_cases, sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd4d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30', '2018', '2015', '5']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "digits = r\"\\d+\"\n",
    "\n",
    "\n",
    "print(re.findall(digits, sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad458fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#Python', '#Rstats', '#R']\n"
     ]
    }
   ],
   "source": [
    "# Looking for words with hash tags\n",
    "wild_card = r\"[#]\\w+\"\n",
    "\n",
    "print(re.findall(wild_card, sample_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fc9e6",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c85719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'My\", 'name', 'is', 'Ntandoyenkosi', 'Matshisela,', 'a', '30', 'year', 'old', 'data', 'analyst', 'from', 'Zimbabwe.', 'I', 'did', 'my', 'Masters', 'degree', 'at', 'the', 'National', 'University', 'of', 'Science', 'and', 'Technology,', 'Zimbabwe,', 'where', 'I', 'specialised', 'in', 'Operations', 'Research', 'and', 'Statistics,', '2018.', 'Prior', 'to', 'this', 'I', 'did', 'a', 'BSc', 'in', 'Operations', 'Research', 'and', 'Statistics', 'finishing', 'it', 'in', '2015.', 'My', 'research', 'interests', 'are', 'statistical', 'computing', 'and', 'machine', 'learning.üòä', 'Most', 'of', 'the', 'times,', 'like', '5', 'times', 'a', 'week,', 'I', 'tweet', 'about', '#Python,', '#Rstats', 'and', '#R.', 'The', 'tweeter', 'handle', 'is', '@matshiselaüòÇ.', '‚óò≈¶,', '‚Ç¶', '‚úî', 'I', 'love', 'giftsüéÅ,', 'pizza', 'üçï,', \"sandwichü•™'\"]\n"
     ]
    }
   ],
   "source": [
    "# Split by space\n",
    "space_words = r\"\\s+\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(space_words, sample_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b663c",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d6dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd569e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'My\",\n",
       " 'name',\n",
       " 'is',\n",
       " 'Ntandoyenkosi',\n",
       " 'Matshisela',\n",
       " ',',\n",
       " 'a',\n",
       " '30',\n",
       " 'year',\n",
       " 'old',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'from',\n",
       " 'Zimbabwe',\n",
       " '.',\n",
       " 'I',\n",
       " 'did',\n",
       " 'my',\n",
       " 'Masters',\n",
       " 'degree']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenize(sample_text)\n",
    "word_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e47ddd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'My name is Ntandoyenkosi Matshisela, a 30 year old data analyst from Zimbabwe.\",\n",
       " 'I did my Masters degree at the National University of Science and Technology, Zimbabwe, where I specialised in Operations Research and Statistics, 2018.',\n",
       " 'Prior to this I did a BSc in Operations Research and Statistics finishing it in 2015.',\n",
       " 'My research interests are statistical computing and machine learning.üòä \\n Most of the times, like 5 times a week, I tweet about #Python, #Rstats and #R. The tweeter handle is @matshiselaüòÇ.',\n",
       " \"‚óò≈¶, ‚Ç¶ ‚úî \\n  I love giftsüéÅ, pizza üçï, sandwichü•™'\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentences\n",
    "sent_tokens = sent_tokenize(sample_text)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ab518",
   "metadata": {},
   "source": [
    "## Advanced tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936d8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00caaf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Python', '#Rstats', '#R']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern1 = r\"#\\w+\"\n",
    "hashtags = regexp_tokenize(sample_text, pattern1)\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a764c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Python', '#Rstats', '#R', '@matshisela']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern2 = r\"[.@#]\\w+\"\n",
    "mention_hashtags = regexp_tokenize(sample_text, pattern2)\n",
    "mention_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24dc6cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"'\"], ['M'], ['y'], [], ['n'], ['a'], ['m'], ['e'], [], ['i']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in sample_text]\n",
    "all_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb391a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'üòä', 'üòÇ', '‚úî', 'üéÅ', 'üçï', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "## Non ascii tokenization\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(sample_text, emoji))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b0179",
   "metadata": {},
   "source": [
    "## Charting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c70d6409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = word_tokenize(sample_text)\n",
    "word_lengths = [len(w) for w in words]\n",
    "plt.hist(word_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b615f",
   "metadata": {},
   "source": [
    "## Word Counts with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61773da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 10), ('i', 5), ('and', 5), ('.', 4), ('a', 3), ('the', 3), ('in', 3), ('research', 3), ('#', 3), ('is', 2)]\n"
     ]
    }
   ],
   "source": [
    "## Word Counts with bag of words\n",
    "from collections import Counter\n",
    "\n",
    "# lets convert words to lower case so that we capture all words the same\n",
    "tokens = word_tokenize(sample_text)\n",
    "\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "word_number = Counter(lower_tokens)\n",
    "print(word_number.most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb2943",
   "metadata": {},
   "source": [
    "## Simple Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fc7e9",
   "metadata": {},
   "source": [
    "There are 3 pre-processing tasks one can do which are\n",
    "1. Lemmatization\n",
    "2. Lowercasing\n",
    "3. Removing unwanted tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcff3a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'is',\n",
       " 'ntandoyenkosi',\n",
       " 'matshisela',\n",
       " 'a',\n",
       " 'year',\n",
       " 'old',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'from']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look for alphabetic words\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
    "alpha_only[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00ab9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'ntandoyenkosi',\n",
       " 'matshisela',\n",
       " 'year',\n",
       " 'old',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'from',\n",
       " 'zimbabwe',\n",
       " 'masters']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us remove stop words, shall we\n",
    "english_stops = ['the', 'they', 'i', 'my', 'to', 'and', 'a', 'in', 'is', 'did', 'of']\n",
    "no_stops = [t for t in alpha_only if t not in english_stops]\n",
    "no_stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35fc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk. stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c5178c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('research', 3), ('zimbabwe', 2), ('operation', 2), ('statistic', 2), ('time', 2), ('name', 1), ('ntandoyenkosi', 1), ('matshisela', 1), ('year', 1), ('old', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Bag of words\n",
    "word_number2 = Counter(lemmatized)\n",
    "print(word_number2.most_common((10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
